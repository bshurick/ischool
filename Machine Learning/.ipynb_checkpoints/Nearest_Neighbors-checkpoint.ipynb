{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and test a Nearest Neighbors classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the relevant packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Iris data to use for experiments. The data include 50 observations of each of 3 types of irises (150 total). Each observation includes 4 measurements: sepal and petal width and height. The goal is to predict the iris type from these measurements.\n",
    "\n",
    "<http://en.wikipedia.org/wiki/Iris_flower_data_set>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris target names: ['setosa' 'versicolor' 'virginica']\n",
      "Iris feature names: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "# Load the data, which is included in sklearn.\n",
    "iris = load_iris()\n",
    "print 'Iris target names:', iris.target_names\n",
    "print 'Iris feature names:', iris.feature_names\n",
    "X, Y = iris.data, iris.target\n",
    "\n",
    "# Shuffle the data, but make sure that the features and accompanying labels stay in sync.\n",
    "np.random.seed(0)  #  To ensure repeatability of results\n",
    "shuffle = np.random.permutation(np.arange(X.shape[0]))\n",
    "X, Y = X[shuffle], Y[shuffle]\n",
    "\n",
    "# Split into train and test.\n",
    "train_data, train_labels = X[:100], Y[:100]\n",
    "test_data, test_labels = X[100:], Y[100:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a distance function that returns the distance between 2 observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##  Note: the assumption is len (v1) == len (v2)\n",
    "def EuclideanDistance(v1, v2):\n",
    "    sum = 0.0\n",
    "    for index in range(len(v1)):\n",
    "        sum += (v1[index] - v2[index]) ** 2\n",
    "    return sum ** 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just an example of code for Euclidean distance.  In order to create a robust production-quality code, you have to be prepared for situations where len(v1) != len (v2): missing data; bad data; wrong data types, etc.  Make sure your functions are always prepared for such scenarios: as much as 50% of a data scientists' job is cleaning up the data.  A great overview of \"what can go wrong with data\" is, e.g., in this book:  http://www.amazon.com/Bad-Data-Handbook-Cleaning-Back/dp/1449321887.\n",
    "\n",
    "Just for fun, let's compute all the pairwise distances in the training data and plot a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEACAYAAACj0I2EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+D+lsTXdcotvVgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x3a1b668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dists = []\n",
    "for i in range(len(train_data) - 1):\n",
    "    for j in range(i + 1, len(train_data)):\n",
    "        dist = EuclideanDistance(train_data[i], train_data[j])\n",
    "        dists.append(dist)\n",
    "        \n",
    "fig = plt.hist(dists, 100) ## Play with different values of the parameter; see how the view changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok now let's create a class that implements a Nearest Neighbors classifier. We'll model it after the sklearn classifier implementations, with fit() and predict() methods.\n",
    "\n",
    "<http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class NearestNeighbors:\n",
    "    # Initialize an instance of the class.\n",
    "    def __init__(self, metric=EuclideanDistance):\n",
    "        self.metric = metric\n",
    "    \n",
    "    # No training for Nearest Neighbors. Just store the data.\n",
    "    def fit(self, train_data, train_labels):\n",
    "        self.train_data = train_data\n",
    "        self.train_labels = train_labels\n",
    "    \n",
    "    # Make predictions for each test example and return results.\n",
    "    def predict(self, test_data):\n",
    "        results = []\n",
    "        for item in test_data:\n",
    "            results.append(self._predict_item(item))\n",
    "        return results\n",
    "    \n",
    "    # Private function for making a single prediction.\n",
    "    def _predict_item(self, item):\n",
    "        best_dist, best_label = 1.0e10, None\n",
    "        for i in range(len(self.train_data)):\n",
    "            dist = self.metric(self.train_data[i], item)\n",
    "            if dist < best_dist:\n",
    "                best_label = self.train_labels[i]\n",
    "                best_dist = dist\n",
    "        return best_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run an experiment with the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total:  50  correct:  48  accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "clf = NearestNeighbors()\n",
    "clf.fit(train_data, train_labels)\n",
    "preds = clf.predict(test_data)\n",
    "\n",
    "correct, total = 0, 0\n",
    "for pred, label in zip(preds, test_labels):\n",
    "    if pred == label: correct += 1\n",
    "    total += 1\n",
    "print 'total: %3d  correct: %3d  accuracy: %3.2f' %(total, correct, 1.0*correct/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try and see what happens if we do not set the seed for the random number generator.  When no seed is given, RNG usually sets the seed to the numeric interpretation of UTC (Coordinated Universal Time).  Let us do just that (change the second argument in range() function before you run this loop):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143181189912\n",
      "seed: 1431811899 total:  50  correct:  49  accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "X, Y = iris.data, iris.target\n",
    "import time\n",
    "Now = time.time()\n",
    "print long (Now.real * 100)\n",
    "\n",
    "# Now run the same codeShuffle the data, but make sure that the features and accompanying labels stay in sync.\n",
    "for i in range (0, 1):\n",
    "    myseed = long(Now.real)+i\n",
    "    np.random.seed(myseed)  #  To ensure repeatability of results\n",
    "\n",
    "    shuffle = np.random.permutation(np.arange(X.shape[0]))\n",
    "    X, Y = X[shuffle], Y[shuffle]\n",
    "\n",
    "    # Split into train and test.\n",
    "    train_data, train_labels = X[:100], Y[:100]\n",
    "    test_data, test_labels = X[100:], Y[100:]\n",
    "\n",
    "    clf.fit(train_data, train_labels)\n",
    "    preds = clf.predict(test_data)\n",
    "\n",
    "    correct, total = 0, 0\n",
    "    for pred, label in zip(preds, test_labels):\n",
    "        if pred == label: correct += 1\n",
    "        total += 1\n",
    "    print 'seed: %ld total: %3d  correct: %3d  accuracy: %3.2f' %(myseed, total, correct, 1.0*correct/total)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy varies with the random seed.  It is normal and expected.  It is important to be aware of this phenomenon: shuffling does matter, and it does affect the classification accuracy.  \n",
    "\n",
    "When you report findings with any ML methodology, or compare your results with someone else's, it is very important to keep it in mind and account for it.\n",
    "\n",
    "As an optional homework, plot the histogram of accuracy after 100 iterations of the Nearest_Neighbors algorithm in this worksheet."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
